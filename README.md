

##################################
########### Base Model ###########
##################################


# random forest
https://github.com/52Pig/paper_reading/blob/master/randomforest2001.pdf

# GBDT
https://github.com/52Pig/paper_reading/blob/master/GBDT-GreedyFuncApproxSS.pdf

# xgboost
https://github.com/52Pig/paper_reading/blob/master/xgboost_1603.02754.pdf

# FFM
https://github.com/52Pig/paper_reading/blob/master/Field-aware%20Factorization%20Machines%20for%20CTR%20Prediction.pdf

# DeepFM
https://github.com/52Pig/paper_reading/blob/master/DeepFM-0239.pdf




# gbdt+lr 融合
https://github.com/52Pig/paper_reading/blob/master/practical-lessons-from-predicting-clicks-on-ads-at-facebook.pdf

# Deep Neural Networks for YouTube Recommendations
https://github.com/52Pig/paper_reading/blob/master/Deep%20Neural%20Networks%20for%20YouTube%20Recommendations.pdf

# DIN 阿里深度兴趣网络
https://github.com/52Pig/paper_reading/blob/master/Deep%20Interest%20Network%20for%20Click-Through%20Rate%20Prediction.1706.06978.pdf



====================================
============ NLP ===================
====================================

# DSSM
https://github.com/52Pig/paper_reading/blob/master/cikm2013_DSSM_fullversion.pdf


# Hin2Vec
https://github.com/52Pig/paper_reading/blob/master/2017.%20CIKM%20HIN2Vec.pdf
# Node2Vec
https://github.com/52Pig/paper_reading/blob/master/node2vec%20Scalable%20Feature%20Learning%20for%20Networks.pdf

# Seq2Seq
https://github.com/52Pig/paper_reading/blob/master/1409.3215.seq2seqwithneuralnetwork.pdf


# transformer训练速度，时间复杂度改进
## Reformer
时间复杂度L*log(L); google开源，数据结构上变化，用到bucket桶和hash，self-attention计算的时候做优化。Reformer：The Efficient Transformer。
https://github.com/52Pig/paper_reading/blob/master/2001.04451v1.pdf

## linformer
时间复杂度L; facebook ai开源，矩阵变换。矩阵操作包含x与w点积，w和qkv矩阵运算，是在x与w过程中进行拆解，x和L矩阵相乘，L和w矩阵相乘，这两部分进行优化，将复杂度转成线性的。Linformer：Self-Attention with Linear Complexity
https://github.com/52Pig/paper_reading/blob/master/Linformer%20Self-Attention%20with%20Linear%20Complexity.pdf

## Memory Transformer.2006.11527
https://github.com/52Pig/paper_reading/blob/master/Memory%20Transformer.2006.11527.pdf


# FastBERT
bert针对推理速度的优化
https://github.com/52Pig/paper_reading/blob/master/2004.02178.pdf

##################################
##### ACL 2020 优质论文 ##########
##################################

https://github.com/52Pig/paper_reading/blob/master/A%20Fine-grained%20Multimedia%20Knowledge%20Extraction%20System.2020.acl-demos.11.pdf
https://github.com/52Pig/paper_reading/blob/master/A%20System%20to%20Support%20the%20Analysis.2020.acl-demos.32.pdf

Don't Stop Pretraining: Adapt Language Models to Domains and Tasks.
https://github.com/52Pig/paper_reading/blob/master/Beyond%20Accuracy%20Behavioral%20Testing%20of%20NLP%20Models%20with%20CheckList.2020.acl-main.442.pdf
Climbing towards NLU On Meaning, Form, and Understanding in the Age of Data.2020.acl-main.463
https://github.com/52Pig/paper_reading/blob/master/Climbing%20towards%20NLU%20On%20Meaning%2C%20Form%2C%20and%20Understanding%20in%20the%20Age%20of%20Data.2020.acl-main.463.pdf
Don’t Stop Pretraining Adapt Language Models to Domains and Tasks.2020.acl-main.740
https://github.com/52Pig/paper_reading/blob/master/Don%E2%80%99t%20Stop%20Pretraining%20Adapt%20Language%20Models%20to%20Domains%20and%20Tasks.2020.acl-main.740.pdf
How Can We Accelerate Progress Towards Human-like Linguistic.2020.acl-main.465
https://github.com/52Pig/paper_reading/blob/master/How%20Can%20We%20Accelerate%20Progress%20Towards%20Human-like%20Linguistic.2020.acl-main.465.pdf









# 其他
人群扩散-基于在线社交广告
https://github.com/52Pig/paper_reading/blob/master/Audience%20Expansion%20for%20Online%20Social%20Network%20Advertising.pdf

Mastering the game of Go without.nature24270
https://github.com/52Pig/paper_reading/blob/master/Mastering%20the%20game%20of%20Go%20without.nature24270.pdf


